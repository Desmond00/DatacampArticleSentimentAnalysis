{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOwsuGQQY9OL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.utils as ku \n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up random seed for reproducibility of work\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preparing the training data\n",
    "new_train_frame = pd.read_csv('./GoodData/final_data_extended_labeledPhase1 - final_data_extended_labeledPhase2.csv')\n",
    "new_train_frame.drop(new_train_frame[new_train_frame['label'].isna()==True].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(new_train_frame['comment'], new_train_frame['label'], \\\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "corpus = X_train.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating word predictor for all training set comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRnDnCW-Z7qv"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture for the word prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9vH8Y59ajYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 294, 64)           212992    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                23000     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 120)               6120      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3328)              402688    \n",
      "=================================================================\n",
      "Total params: 644,800\n",
      "Trainable params: 644,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIg2f1HBxqof",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16835 samples\n",
      "Epoch 1/100\n",
      "16835/16835 [==============================] - 16s 972us/sample - loss: 6.9623 - accuracy: 0.0372\n",
      "Epoch 2/100\n",
      "16835/16835 [==============================] - 16s 943us/sample - loss: 6.5131 - accuracy: 0.0434- loss: 6.5137 \n",
      "Epoch 3/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 6.1547 - accuracy: 0.0555\n",
      "Epoch 4/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 5.8530 - accuracy: 0.0719\n",
      "Epoch 5/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 5.5752 - accuracy: 0.0877\n",
      "Epoch 6/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 5.3125 - accuracy: 0.1037\n",
      "Epoch 7/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 5.0699 - accuracy: 0.1187\n",
      "Epoch 8/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 4.8306 - accuracy: 0.1377\n",
      "Epoch 9/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 4.5953 - accuracy: 0.1562\n",
      "Epoch 10/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 4.3593 - accuracy: 0.1748\n",
      "Epoch 11/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 4.1240 - accuracy: 0.1951\n",
      "Epoch 12/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 3.8843 - accuracy: 0.2149\n",
      "Epoch 13/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 3.6469 - accuracy: 0.2400\n",
      "Epoch 14/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 3.4101 - accuracy: 0.2703\n",
      "Epoch 15/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 3.1756 - accuracy: 0.3045\n",
      "Epoch 16/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 2.9516 - accuracy: 0.3386\n",
      "Epoch 17/100\n",
      "16835/16835 [==============================] - 16s 961us/sample - loss: 2.7319 - accuracy: 0.3821\n",
      "Epoch 18/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 2.5333 - accuracy: 0.4223\n",
      "Epoch 19/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 2.3456 - accuracy: 0.4591\n",
      "Epoch 20/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 2.1716 - accuracy: 0.4908\n",
      "Epoch 21/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 2.0188 - accuracy: 0.5227\n",
      "Epoch 22/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.8793 - accuracy: 0.5505\n",
      "Epoch 23/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.7511 - accuracy: 0.5766\n",
      "Epoch 24/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.6247 - accuracy: 0.6065\n",
      "Epoch 25/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.5176 - accuracy: 0.6279\n",
      "Epoch 26/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 1.4209 - accuracy: 0.6514\n",
      "Epoch 27/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.3248 - accuracy: 0.6712\n",
      "Epoch 28/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.2403 - accuracy: 0.6964\n",
      "Epoch 29/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.1573 - accuracy: 0.7104\n",
      "Epoch 30/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.0819 - accuracy: 0.7308\n",
      "Epoch 31/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 1.0169 - accuracy: 0.7449\n",
      "Epoch 32/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.9474 - accuracy: 0.7613\n",
      "Epoch 33/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.8916 - accuracy: 0.7771\n",
      "Epoch 34/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.8299 - accuracy: 0.7922\n",
      "Epoch 35/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.7762 - accuracy: 0.8055\n",
      "Epoch 36/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.7263 - accuracy: 0.8173\n",
      "Epoch 37/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.6800 - accuracy: 0.8293\n",
      "Epoch 38/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.6327 - accuracy: 0.8425\n",
      "Epoch 39/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.5997 - accuracy: 0.8522\n",
      "Epoch 40/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.5605 - accuracy: 0.8581\n",
      "Epoch 41/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.5248 - accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.4932 - accuracy: 0.8768\n",
      "Epoch 43/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.4612 - accuracy: 0.8836\n",
      "Epoch 44/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.4351 - accuracy: 0.8922\n",
      "Epoch 45/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.3943 - accuracy: 0.9032\n",
      "Epoch 46/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.3807 - accuracy: 0.9072\n",
      "Epoch 47/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.3772 - accuracy: 0.9045\n",
      "Epoch 48/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.3371 - accuracy: 0.9180\n",
      "Epoch 49/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.3151 - accuracy: 0.9226\n",
      "Epoch 50/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 0.2964 - accuracy: 0.9275\n",
      "Epoch 51/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2853 - accuracy: 0.9305\n",
      "Epoch 52/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2786 - accuracy: 0.9293\n",
      "Epoch 53/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2721 - accuracy: 0.9313\n",
      "Epoch 54/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2497 - accuracy: 0.9371\n",
      "Epoch 55/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2438 - accuracy: 0.9382\n",
      "Epoch 56/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2190 - accuracy: 0.9461\n",
      "Epoch 57/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2096 - accuracy: 0.9475\n",
      "Epoch 58/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2074 - accuracy: 0.9490\n",
      "Epoch 59/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.2058 - accuracy: 0.9482\n",
      "Epoch 60/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 0.2177 - accuracy: 0.9443\n",
      "Epoch 61/100\n",
      "16835/16835 [==============================] - 20s 1ms/sample - loss: 0.1943 - accuracy: 0.9502\n",
      "Epoch 62/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1753 - accuracy: 0.9566\n",
      "Epoch 63/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1634 - accuracy: 0.9603\n",
      "Epoch 64/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1627 - accuracy: 0.9591\n",
      "Epoch 65/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1784 - accuracy: 0.9540\n",
      "Epoch 66/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1922 - accuracy: 0.9486\n",
      "Epoch 67/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1672 - accuracy: 0.9576\n",
      "Epoch 68/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1540 - accuracy: 0.9609\n",
      "Epoch 69/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1450 - accuracy: 0.9626\n",
      "Epoch 70/100\n",
      "16835/16835 [==============================] - 16s 929us/sample - loss: 0.1363 - accuracy: 0.9639\n",
      "Epoch 71/100\n",
      "16835/16835 [==============================] - 17s 1ms/sample - loss: 0.1448 - accuracy: 0.9619\n",
      "Epoch 72/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1528 - accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1582 - accuracy: 0.9577\n",
      "Epoch 74/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1571 - accuracy: 0.9559\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1422 - accuracy: 0.9610\n",
      "Epoch 76/100\n",
      "16835/16835 [==============================] - 19s 1ms/sample - loss: 0.1436 - accuracy: 0.9618\n",
      "Epoch 77/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1296 - accuracy: 0.9639\n",
      "Epoch 78/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1127 - accuracy: 0.9691\n",
      "Epoch 79/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1145 - accuracy: 0.9689\n",
      "Epoch 80/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1317 - accuracy: 0.9636\n",
      "Epoch 81/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1590 - accuracy: 0.9541\n",
      "Epoch 82/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1588 - accuracy: 0.9543\n",
      "Epoch 83/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1228 - accuracy: 0.9651\n",
      "Epoch 84/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1064 - accuracy: 0.9700\n",
      "Epoch 85/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.0998 - accuracy: 0.9711\n",
      "Epoch 86/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1023 - accuracy: 0.9698\n",
      "Epoch 87/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1329 - accuracy: 0.9612\n",
      "Epoch 88/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1979 - accuracy: 0.9430\n",
      "Epoch 89/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1340 - accuracy: 0.9606\n",
      "Epoch 90/100\n",
      "16835/16835 [==============================] - 17s 1ms/sample - loss: 0.1027 - accuracy: 0.9693\n",
      "Epoch 91/100\n",
      "16835/16835 [==============================] - 16s 932us/sample - loss: 0.0942 - accuracy: 0.9710\n",
      "Epoch 92/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.0949 - accuracy: 0.9714\n",
      "Epoch 93/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.0961 - accuracy: 0.9710\n",
      "Epoch 94/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1223 - accuracy: 0.9641\n",
      "Epoch 95/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1980 - accuracy: 0.9404\n",
      "Epoch 96/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1320 - accuracy: 0.9612\n",
      "Epoch 97/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.1075 - accuracy: 0.9686\n",
      "Epoch 98/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.0954 - accuracy: 0.9702\n",
      "Epoch 99/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.0907 - accuracy: 0.9719\n",
      "Epoch 100/100\n",
      "16835/16835 [==============================] - 18s 1ms/sample - loss: 0.0935 - accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fXTEO3GJ282",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./modelBackup/WordPredictionOnTrainData/model.h5')\n",
    "model.save_weights('./modelBackup/WordPredictionOnTrainData/weights.h5')\n",
    "with open('./modelBackup/WordPredictionOnTrainData/history.pkl', 'wb') as historyFile:\n",
    "    pickle.dump(history.history, historyFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with some existing data from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Vc6PHgxa6Hm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you so much for sharing a ground-level comprehension of the nuts and bolts. watch a mess. Â but better can python training and chennai /a you for posting.more info : web design pakistan service and get the best price information to the union. really great like to use you need to mac support phone number mcafee customer service number is 24/7 24/7 printer printer setup updates regarding any queries on installation canon setup canon printer setup canon printer issues related issue. if anyone face printer issue click every video technician or one error code 9999 quickbooks error h101 h202 h303 or h505\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Thank you\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now making the word prediction specific to Spam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamDF = new_train_frame[new_train_frame.label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = spamDF['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*,;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 94, 64)            75392     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 50)                23000     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 120)               6120      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1178)              142538    \n",
      "=================================================================\n",
      "Total params: 247,050\n",
      "Trainable params: 247,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(50))\n",
    "# Added regularization for maintaining versatality in the generated text\n",
    "model.add(Dense(120, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3578 samples\n",
      "Epoch 1/100\n",
      "3578/3578 [==============================] - 2s 629us/sample - loss: 6.9464 - accuracy: 0.0268\n",
      "Epoch 2/100\n",
      "3578/3578 [==============================] - 1s 418us/sample - loss: 6.2673 - accuracy: 0.0246\n",
      "Epoch 3/100\n",
      "3578/3578 [==============================] - 1s 417us/sample - loss: 6.0651 - accuracy: 0.0232 - loss: 6.0\n",
      "Epoch 4/100\n",
      "3578/3578 [==============================] - ETA: 0s - loss: 5.9539 - accuracy: 0.02 - 1s 416us/sample - loss: 5.9568 - accuracy: 0.0282\n",
      "Epoch 5/100\n",
      "3578/3578 [==============================] - 1s 419us/sample - loss: 5.8885 - accuracy: 0.0313\n",
      "Epoch 6/100\n",
      "3578/3578 [==============================] - 1s 417us/sample - loss: 5.8417 - accuracy: 0.0402 - loss: 5.870\n",
      "Epoch 7/100\n",
      "3578/3578 [==============================] - 1s 417us/sample - loss: 5.7943 - accuracy: 0.0442\n",
      "Epoch 8/100\n",
      "3578/3578 [==============================] - 1s 419us/sample - loss: 5.7370 - accuracy: 0.0495 - los\n",
      "Epoch 9/100\n",
      "3578/3578 [==============================] - 1s 417us/sample - loss: 5.6668 - accuracy: 0.0584\n",
      "Epoch 10/100\n",
      "3578/3578 [==============================] - 1s 414us/sample - loss: 5.6054 - accuracy: 0.0615\n",
      "Epoch 11/100\n",
      "3578/3578 [==============================] - 1s 418us/sample - loss: 5.5421 - accuracy: 0.0671\n",
      "Epoch 12/100\n",
      "3578/3578 [==============================] - 1s 419us/sample - loss: 5.4820 - accuracy: 0.0688\n",
      "Epoch 13/100\n",
      "3578/3578 [==============================] - 1s 419us/sample - loss: 5.4294 - accuracy: 0.0696\n",
      "Epoch 14/100\n",
      "3578/3578 [==============================] - 1s 418us/sample - loss: 5.3794 - accuracy: 0.0707\n",
      "Epoch 15/100\n",
      "3578/3578 [==============================] - 1s 418us/sample - loss: 5.3313 - accuracy: 0.0735\n",
      "Epoch 16/100\n",
      "3578/3578 [==============================] - 2s 427us/sample - loss: 5.2877 - accuracy: 0.0774\n",
      "Epoch 17/100\n",
      "3578/3578 [==============================] - 2s 423us/sample - loss: 5.2344 - accuracy: 0.0783 - loss: 5.2252 - accuracy\n",
      "Epoch 18/100\n",
      "3578/3578 [==============================] - 1s 419us/sample - loss: 5.1895 - accuracy: 0.0824\n",
      "Epoch 19/100\n",
      "3578/3578 [==============================] - 1s 419us/sample - loss: 5.1444 - accuracy: 0.0847\n",
      "Epoch 20/100\n",
      "3578/3578 [==============================] - 1s 417us/sample - loss: 5.1008 - accuracy: 0.0872\n",
      "Epoch 21/100\n",
      "3578/3578 [==============================] - 2s 421us/sample - loss: 5.0558 - accuracy: 0.0880\n",
      "Epoch 22/100\n",
      "3578/3578 [==============================] - 1s 419us/sample - loss: 5.0115 - accuracy: 0.0942\n",
      "Epoch 23/100\n",
      "3578/3578 [==============================] - 2s 425us/sample - loss: 4.9658 - accuracy: 0.0995\n",
      "Epoch 24/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 4.9258 - accuracy: 0.1017\n",
      "Epoch 25/100\n",
      "3578/3578 [==============================] - 2s 442us/sample - loss: 4.8814 - accuracy: 0.1042\n",
      "Epoch 26/100\n",
      "3578/3578 [==============================] - 2s 433us/sample - loss: 4.8384 - accuracy: 0.1098\n",
      "Epoch 27/100\n",
      "3578/3578 [==============================] - 2s 435us/sample - loss: 4.7903 - accuracy: 0.1124\n",
      "Epoch 28/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 4.7485 - accuracy: 0.1171\n",
      "Epoch 29/100\n",
      "3578/3578 [==============================] - 2s 433us/sample - loss: 4.7078 - accuracy: 0.1207\n",
      "Epoch 30/100\n",
      "3578/3578 [==============================] - 2s 437us/sample - loss: 4.6601 - accuracy: 0.1316\n",
      "Epoch 31/100\n",
      "3578/3578 [==============================] - 2s 433us/sample - loss: 4.6185 - accuracy: 0.1328\n",
      "Epoch 32/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 4.5697 - accuracy: 0.1428\n",
      "Epoch 33/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 4.5267 - accuracy: 0.1459\n",
      "Epoch 34/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 4.4880 - accuracy: 0.1518\n",
      "Epoch 35/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 4.4408 - accuracy: 0.1557\n",
      "Epoch 36/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 4.3914 - accuracy: 0.1632\n",
      "Epoch 37/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 4.3488 - accuracy: 0.1696\n",
      "Epoch 38/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 4.3015 - accuracy: 0.1752\n",
      "Epoch 39/100\n",
      "3578/3578 [==============================] - 2s 440us/sample - loss: 4.2563 - accuracy: 0.1881 - loss: 4.255\n",
      "Epoch 40/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 4.2083 - accuracy: 0.1926\n",
      "Epoch 41/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 4.1654 - accuracy: 0.1962\n",
      "Epoch 42/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 4.1191 - accuracy: 0.2093\n",
      "Epoch 43/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 4.0713 - accuracy: 0.2119\n",
      "Epoch 44/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 4.0215 - accuracy: 0.2169\n",
      "Epoch 45/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 3.9758 - accuracy: 0.2211\n",
      "Epoch 46/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 3.9278 - accuracy: 0.2364\n",
      "Epoch 47/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 3.8802 - accuracy: 0.2437\n",
      "Epoch 48/100\n",
      "3578/3578 [==============================] - 2s 435us/sample - loss: 3.8373 - accuracy: 0.2485\n",
      "Epoch 49/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 3.7933 - accuracy: 0.2513\n",
      "Epoch 50/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 3.7458 - accuracy: 0.2616\n",
      "Epoch 51/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 3.6972 - accuracy: 0.2691 - - ETA: 0s - loss: 3.659\n",
      "Epoch 52/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 3.6544 - accuracy: 0.2661\n",
      "Epoch 53/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 3.6045 - accuracy: 0.2862\n",
      "Epoch 54/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 3.5589 - accuracy: 0.2907\n",
      "Epoch 55/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 3.5104 - accuracy: 0.2946\n",
      "Epoch 56/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 3.4654 - accuracy: 0.3027\n",
      "Epoch 57/100\n",
      "3578/3578 [==============================] - 2s 433us/sample - loss: 3.4196 - accuracy: 0.3074\n",
      "Epoch 58/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 3.3737 - accuracy: 0.3236\n",
      "Epoch 59/100\n",
      "3578/3578 [==============================] - 2s 433us/sample - loss: 3.3229 - accuracy: 0.3267\n",
      "Epoch 60/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 3.2741 - accuracy: 0.3373\n",
      "Epoch 61/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 3.2289 - accuracy: 0.3488\n",
      "Epoch 62/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 3.1902 - accuracy: 0.3482\n",
      "Epoch 63/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 3.1367 - accuracy: 0.3628\n",
      "Epoch 64/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 3.0963 - accuracy: 0.3667\n",
      "Epoch 65/100\n",
      "3578/3578 [==============================] - 2s 428us/sample - loss: 3.0464 - accuracy: 0.3804\n",
      "Epoch 66/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 2.9965 - accuracy: 0.3932\n",
      "Epoch 67/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 2.9573 - accuracy: 0.4022\n",
      "Epoch 68/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 2.9087 - accuracy: 0.4100\n",
      "Epoch 69/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 2.8554 - accuracy: 0.4229\n",
      "Epoch 70/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 2.8167 - accuracy: 0.4310\n",
      "Epoch 71/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 2.7693 - accuracy: 0.4466\n",
      "Epoch 72/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 2.7246 - accuracy: 0.4586\n",
      "Epoch 73/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 2.6791 - accuracy: 0.4754\n",
      "Epoch 74/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 2.6380 - accuracy: 0.4863\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3578/3578 [==============================] - 2s 429us/sample - loss: 2.5966 - accuracy: 0.4986\n",
      "Epoch 76/100\n",
      "3578/3578 [==============================] - 2s 425us/sample - loss: 2.5577 - accuracy: 0.5101\n",
      "Epoch 77/100\n",
      "3578/3578 [==============================] - 2s 428us/sample - loss: 2.5157 - accuracy: 0.5210\n",
      "Epoch 78/100\n",
      "3578/3578 [==============================] - 2s 424us/sample - loss: 2.4793 - accuracy: 0.5279\n",
      "Epoch 79/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 2.4348 - accuracy: 0.5632\n",
      "Epoch 80/100\n",
      "3578/3578 [==============================] - 2s 425us/sample - loss: 2.4004 - accuracy: 0.5674\n",
      "Epoch 81/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 2.3627 - accuracy: 0.5657\n",
      "Epoch 82/100\n",
      "3578/3578 [==============================] - 2s 447us/sample - loss: 2.3181 - accuracy: 0.5900\n",
      "Epoch 83/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 2.2852 - accuracy: 0.5975\n",
      "Epoch 84/100\n",
      "3578/3578 [==============================] - 2s 433us/sample - loss: 2.2542 - accuracy: 0.6121\n",
      "Epoch 85/100\n",
      "3578/3578 [==============================] - 2s 434us/sample - loss: 2.2211 - accuracy: 0.6098\n",
      "Epoch 86/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 2.1828 - accuracy: 0.6311\n",
      "Epoch 87/100\n",
      "3578/3578 [==============================] - 2s 428us/sample - loss: 2.1503 - accuracy: 0.6397\n",
      "Epoch 88/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 2.1192 - accuracy: 0.6470\n",
      "Epoch 89/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 2.0924 - accuracy: 0.6532\n",
      "Epoch 90/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 2.0541 - accuracy: 0.6613 - loss: 2.0463 - \n",
      "Epoch 91/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 2.0274 - accuracy: 0.6660\n",
      "Epoch 92/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 1.9972 - accuracy: 0.6792\n",
      "Epoch 93/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 1.9704 - accuracy: 0.6836\n",
      "Epoch 94/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 1.9348 - accuracy: 0.6926\n",
      "Epoch 95/100\n",
      "3578/3578 [==============================] - 2s 432us/sample - loss: 1.9043 - accuracy: 0.7113\n",
      "Epoch 96/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 1.8809 - accuracy: 0.7113\n",
      "Epoch 97/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 1.8532 - accuracy: 0.7116\n",
      "Epoch 98/100\n",
      "3578/3578 [==============================] - 2s 429us/sample - loss: 1.8224 - accuracy: 0.7267\n",
      "Epoch 99/100\n",
      "3578/3578 [==============================] - 2s 430us/sample - loss: 1.7965 - accuracy: 0.7297\n",
      "Epoch 100/100\n",
      "3578/3578 [==============================] - 2s 431us/sample - loss: 1.7845 - accuracy: 0.7309 - loss: 1.7441 - ac\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./modelBackup/WordPredictionOnTrainSpamData/model.h5')\n",
    "model.save_weights('./modelBackup/WordPredictionOnTrainSpamData/weights.h5')\n",
    "with open('./modelBackup/WordPredictionOnTrainSpamData/history.pkl', 'wb') as historyFile:\n",
    "    pickle.dump(history.history, historyFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom helper function to generate sentences using the trained model by selecting minWords from randomly selected existing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSentences(noOfSentences, existingSentences, minWords=2):\n",
    "    generatedSentences = []\n",
    "    for sentenceIterator in range(noOfSentences):\n",
    "        randomSentence = random.choice(existingSentences)\n",
    "        sentenceWordCount = len(randomSentence.split(' '))\n",
    "        partialSentence = ' '.join(randomSentence.split(' ')[0: minWords if sentenceWordCount > minWords else sentenceWordCount])\n",
    "        seed_text = partialSentence\n",
    "        next_words = sentenceWordCount - 2\n",
    "\n",
    "        for _ in range(next_words):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "            predicted = model.predict_classes(token_list, verbose=0)\n",
    "            output_word = \"\"\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == predicted:\n",
    "                    output_word = word\n",
    "                    break\n",
    "            seed_text += \" \" + output_word\n",
    "        generatedSentences.append(seed_text)\n",
    "    return generatedSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedSentences = generateSentences(200, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the generated data to existing data for our final classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_frame.drop('articleName', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedSpamData = list(zip(generatedSentences, [1.0]*len(generatedSentences)))\n",
    "generatedFrame = pd.DataFrame(generatedSpamData, columns=['comment', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_frame = shuffle(new_train_frame.append(generatedFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_frame.to_csv('./OriginalPlusGeneratedData.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP-Week4-Exercise-Shakespeare-Question.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
